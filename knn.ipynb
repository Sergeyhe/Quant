{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.neighbors import (KNeighborsClassifier, \n",
    "                               KNeighborsRegressor)\n",
    "from sklearn.model_selection import (cross_val_predict,\n",
    "                                     cross_val_score,\n",
    "                                     GridSearchCV)\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.preprocessing import StandardScaler, scale\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import make_scorer\n",
    "from yellowbrick.model_selection import ValidationCurve, LearningCurve\n",
    "\n",
    "sns.set_style('whitegrid')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21613 entries, 0 to 21612\n",
      "Data columns (total 16 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   price          21613 non-null  float64\n",
      " 1   bedrooms       21613 non-null  int64  \n",
      " 2   bathrooms      21613 non-null  float64\n",
      " 3   sqft_living    21613 non-null  int64  \n",
      " 4   sqft_lot       21613 non-null  int64  \n",
      " 5   floors         21613 non-null  float64\n",
      " 6   waterfront     21613 non-null  int64  \n",
      " 7   view           21613 non-null  int64  \n",
      " 8   condition      21613 non-null  int64  \n",
      " 9   grade          21613 non-null  int64  \n",
      " 10  sqft_above     21613 non-null  int64  \n",
      " 11  sqft_basement  21613 non-null  int64  \n",
      " 12  yr_built       21613 non-null  int64  \n",
      " 13  yr_renovated   21613 non-null  int64  \n",
      " 14  sqft_living15  21613 non-null  int64  \n",
      " 15  sqft_lot15     21613 non-null  int64  \n",
      "dtypes: float64(3), int64(13)\n",
      "memory usage: 2.6 MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21613 entries, 0 to 21612\n",
      "Data columns (total 10 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   sqft_living    21613 non-null  int64  \n",
      " 1   grade          21613 non-null  int64  \n",
      " 2   sqft_living15  21613 non-null  int64  \n",
      " 3   sqft_above     21613 non-null  int64  \n",
      " 4   bathrooms      21613 non-null  float64\n",
      " 5   sqft_lot15     21613 non-null  int64  \n",
      " 6   bedrooms       21613 non-null  int64  \n",
      " 7   yr_built       21613 non-null  int64  \n",
      " 8   floors         21613 non-null  float64\n",
      " 9   sqft_basement  21613 non-null  int64  \n",
      "dtypes: float64(2), int64(8)\n",
      "memory usage: 1.6 MB\n"
     ]
    }
   ],
   "source": [
    "### Loading Data - Kings County Housing Data\n",
    "house_sales = pd.read_csv('knn_data.csv')\n",
    "house_sales = house_sales.drop(\n",
    "    ['id','zipcode','lat','long','date'],axis = 1)\n",
    "# 这里使用的drop函数的axis=1参数表示我们是在删除列，而不是行\n",
    "house_sales.info()\n",
    "\n",
    "### Select & Transform Features\n",
    "# 资产价格一般呈现长尾分布\n",
    "#distplot函数是用来绘制直方图并伴随一个核密度估计（Kernel Density Estimation, 简称KDE）曲线的\n",
    "price_distribution = sns.distplot(house_sales.price) \n",
    "price_distribution.set(title = 'Distribution of House Price')\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "\n",
    "### 对数据进行对数变换\n",
    "# practical in coping with skewed data\n",
    "X_all = house_sales.drop('price', axis=1)\n",
    "y = np.log(house_sales.price)\n",
    "# 当处理到含0的数据集时，可以考虑使用loglp\n",
    "\n",
    "## 对数转换后的价格直方图\n",
    "logprice_distribution = sns.displot(y)\n",
    "logprice_distribution.set(title = 'Distribution of House Log Price')\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "\n",
    "# 使用mutual_info_regression函数计算X_all中每个特征与y的互信息\n",
    "# 然后将结果转化为pandas Series，并以X_all的列名作为索引\n",
    "mi_reg = pd.Series(mutual_info_regression(X_all, y),\n",
    "                   index=X_all.columns).sort_values(ascending=False)\n",
    "mi_reg\n",
    "# 选择互信息最高的前10个特征\n",
    "X = X_all.loc[:, mi_reg.iloc[:10].index]\n",
    "\n",
    "# 使用pairplot为X中的每个特征与价格'y'绘制散点图\n",
    "# X.assign(price = y) 临时在X数据框中增加一个'price'列\n",
    "# y_vars指定Y轴变量，而x_vars指定X轴变量\n",
    "# 临时把price加入X中，之后去掉\n",
    "X = X.assign(price=y)\n",
    "g = sns.pairplot(X, y_vars=['price'], x_vars=X.columns)\n",
    "sns.despine()\n",
    "X = X.drop( 'price' , axis = 1)\n",
    "\n",
    "### Explore Correlations\n",
    "X.info()\n",
    "# 使用 Spearman 秩相关系数来计算 X 中每个特征与目标 y 之间的相关性。\n",
    "# 将计算得到的相关系数值绘制为一个水平条形图。\n",
    "Correl = X.apply(lambda x: spearmanr(x,y)[0])\n",
    "Correl.sort_values().plot.barh()\n",
    "\n",
    "### KNN Regression\n",
    "# 对数据进行标准化（Z-score标准化），使得每个特征的均值为0，标准差为1\n",
    "X_scaled = scale(X)\n",
    "# 创建KNN回归模型实例\n",
    "model = KNeighborsRegressor()\n",
    "# 使用标准化后的数据来训练模型\n",
    "model.fit(X=X_scaled, y=y)\n",
    "# 使用训练好的模型预测数据\n",
    "y_pred = model.predict(X_scaled)\n",
    "\n",
    "### 回归误差指标\n",
    "from sklearn.metrics import (mean_squared_error,\n",
    "                             mean_absolute_error,\n",
    "                             mean_squared_log_error,\n",
    "                             median_absolute_error,\n",
    "                             explained_variance_score,\n",
    "                             r2_score)\n",
    "\n",
    "# 计算预测误差\n",
    "# 误差是与真实值的偏差，而残差是与估计值（例如，对总体均值的估计）的偏差。\n",
    "error = (y-y_pred).rename('Prediction Errors')\n",
    "scores = dict(\n",
    "    rmse = np.sqrt(mean_squared_error(y_true=y, y_pred=y_pred)),  # 均方根误差\n",
    "    rmsle = np.sqrt(mean_squared_log_error(y_true=y, y_pred=y_pred)),  # 均方根对数误差\n",
    "    mean_ae = mean_absolute_error(y_true=y, y_pred=y_pred),  # 平均绝对误差\n",
    "    median_ae = median_absolute_error(y_true=y, y_pred=y_pred),  # 中位绝对误差\n",
    "    # explained_variance = explained_variance_score(y_true=y, y_pred=y_pred),  # 解释的方差\n",
    "    r2 = r2_score(y_true=y, y_pred=y_pred)  # R²得分\n",
    ")\n",
    "\n",
    "### 画图\n",
    "# 使用matplotlib创建一个1行3列的子图，整体图形大小为15x4\n",
    "fig, axes = plt.subplots(ncols=3, figsize=(15, 4))\n",
    "\n",
    "# 在第一个子图上绘制实际值与预测值的散点图\n",
    "sns.scatterplot(x=y, y=y_pred, ax=axes[0])\n",
    "axes[0].set_xlabel('Log Price')             # 设置x轴标签为\"Log Price\"\n",
    "axes[0].set_ylabel('Predictions')           # 设置y轴标签为\"Predictions\"\n",
    "axes[0].set_ylim(11, 16)                    # 设置y轴的显示范围从11到16\n",
    "axes[0].set_title('Predicted vs. Actuals')  # 设置第1个子图的标题为\"Predicted vs. Actuals\"\n",
    "\n",
    "# 在第二个子图上绘制error的分布图\n",
    "sns.distplot(error, ax=axes[1])\n",
    "axes[1].set_title('Residuals')              # 设置第2个子图的标题为\"Residuals\"\n",
    "\n",
    "# 在第三个子图上绘制scores的条形图\n",
    "pd.Series(scores).plot.barh(ax=axes[2], title='Error Metrics')  # 设置第3个子图的标题为\"Error Metrics\"\n",
    "\n",
    "# 为整体图形设置一个标题，标题大小为16\n",
    "fig.suptitle('In-Sample Regression Errors', fontsize=16)\n",
    "\n",
    "# 移除图形的上边框和右边框\n",
    "sns.despine()\n",
    "\n",
    "# 调整子图的布局，使其更加紧凑\n",
    "fig.tight_layout()\n",
    "\n",
    "# 调整整体标题的位置\n",
    "fig.subplots_adjust(top=.88)\n",
    "\n",
    "\n",
    "\n",
    "### 交叉验证\n",
    "# 定义计算RMSE的函数\n",
    "def rmse(y_true, pred):\n",
    "    return np.sqrt(mean_squared_error(y_true = y_true, y_pred = pred))\n",
    "\n",
    "# 使用make_scorer函数创建一个RMSE评分器\n",
    "rmse_score = make_scorer(rmse)\n",
    "\n",
    "# 初始化一个字典来存储每个K值的交叉验证结果\n",
    "cv_rmse = {}\n",
    "\n",
    "# 创建一个列表来存储要测试的K值，从1开始，然后是5, 10, 15,..., 50\n",
    "n_neighbors = [1] + list(range(5, 51, 5))\n",
    "\n",
    "# 对每个K值进行交叉验证\n",
    "for n in n_neighbors:\n",
    "    # 创建一个Pipeline，包含两个步骤：1) 数据标准化，2) KNN回归\n",
    "    pipe = Pipeline([('scaler', StandardScaler()),\n",
    "                     ('knn', KNeighborsRegressor(n_neighbors=n))])\n",
    "    \n",
    "    # 使用cross_val_score函数进行5折交叉验证，并存储结果到cv_rmse字典中\n",
    "    cv_rmse[n] = cross_val_score(pipe, \n",
    "                                X=X, \n",
    "                                y=y,\n",
    "                                scoring=rmse_score,\n",
    "                                cv=5)\n",
    "    \n",
    "# 将cv_rmse字典转换为DataFrame格式，方便后续的分析和绘图\n",
    "cv_rmse = pd.DataFrame.from_dict(cv_rmse, orient='index')\n",
    "\n",
    "# 找到平均RMSE最小的K值和对应的RMSE\n",
    "best_n, best_rmse = cv_rmse.mean(1).idxmin(), cv_rmse.mean(1).min()\n",
    "\n",
    "# 调整数据框结构以适应seaborn绘图\n",
    "cv_rmse = cv_rmse.stack().reset_index()\n",
    "cv_rmse.columns =['n', 'fold', 'RMSE']\n",
    "\n",
    "# 使用seaborn绘制每个K值的交叉验证结果\n",
    "ax = sns.lineplot(x='n', y='RMSE', data=cv_rmse)\n",
    "\n",
    "# 设置图的标题，显示最佳K值和对应的RMSE\n",
    "ax.set_title(f'Cross-Validation Results KNN | Best N: {best_n:d} | Best RMSE: {best_rmse:.2f}')\n",
    "\n",
    "\n",
    "\n",
    "### 真实 VS 预测\n",
    "# 使用 Pipeline 结合标准化处理和K近邻回归器\n",
    "pipe = Pipeline([('scaler', StandardScaler()),  # 添加一个名为'scaler'的标准化处理步骤\n",
    "                 ('knn', KNeighborsRegressor(n_neighbors=best_n))])  # 添加一个名为'knn'的K近邻回归步骤\n",
    "\n",
    "# 使用5折交叉验证进行预测\n",
    "y_pred = cross_val_predict(pipe, X, y, cv=5)\n",
    "\n",
    "# 绘制 Y真实值 与 Y预测值 的散点图\n",
    "ax = sns.scatterplot(x=y, y=y_pred)\n",
    "# 创建一个真实值的范围\n",
    "y_range = list(range(int(y.min() + 1), int(y.max() + 1)))\n",
    "# 在同一图上绘制y=x的直线，代表完美预测\n",
    "pd.Series(y_range, index=y_range).plot(ax=ax, lw=2, c='darkred')\n",
    "\n",
    "\n",
    "### 计算交叉验证的误差\n",
    "error = (y - y_pred).rename('Prediction Errors')\n",
    "# 计算并存储各种误差指标\n",
    "scores = dict(\n",
    "    rmse=np.sqrt(mean_squared_error(y_true=y, y_pred=y_pred)),  # 均方根误差\n",
    "    rmsle=np.sqrt(mean_squared_log_error(y_true=y, y_pred=y_pred)),  # 对数均方根误差\n",
    "    mean_ae=mean_absolute_error(y_true=y, y_pred=y_pred),  # 平均绝对误差\n",
    "    median_ae=median_absolute_error(y_true=y, y_pred=y_pred),  # 中位绝对误差\n",
    "    r2score=explained_variance_score(y_true=y, y_pred=y_pred)  # 解释方差得分\n",
    ")\n",
    "\n",
    "# 创建一个1行3列的子图\n",
    "fig, axes = plt.subplots(ncols=3, figsize=(15, 5))\n",
    "# 在第一个子图中绘制真实值与预测值的散点图\n",
    "sns.scatterplot(x=y, y=y_pred, ax=axes[0])\n",
    "axes[0].set_xlabel('Log Price')  # 设置x轴标签\n",
    "axes[0].set_ylabel('Predictions')  # 设置y轴标签\n",
    "axes[0].set_ylim(11, 16)  # 设置y轴的范围\n",
    "# 在第二个子图中绘制误差的分布图\n",
    "sns.distplot(error, ax=axes[1])\n",
    "# 在第三个子图中绘制误差指标的条形图\n",
    "pd.Series(scores).plot.barh(ax=axes[2], title='Error Metrics')  \n",
    "# 设置整体的标题\n",
    "fig.suptitle('Cross-Validation Regression Errors', fontsize=24)\n",
    "# 调整子图的布局\n",
    "fig.tight_layout()\n",
    "# 调整整体标题的位置\n",
    "plt.subplots_adjust(top=.8)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### 使用Pipeline结合GridSearchCV进行参数优化\n",
    "# 创建一个Pipeline，首先进行标准化，然后用KNN回归\n",
    "pipe = Pipeline([('scaler', StandardScaler()),  # 标准化数据\n",
    "                 ('knn', KNeighborsRegressor())])  # KNN回归模型\n",
    "\n",
    "# 设置交叉验证的折数为5\n",
    "n_folds = 5\n",
    "# 设置KNN回归中的邻居数量从5到100，每5个一跳\n",
    "n_neighbors = tuple(range(5, 101, 5))\n",
    "\n",
    "# 创建参数网格，用于GridSearchCV\n",
    "param_grid = {'knn__n_neighbors': n_neighbors}\n",
    "\n",
    "# 创建GridSearchCV估计器，用于寻找最佳参数\n",
    "estimator = GridSearchCV(estimator=pipe,  # 使用上面定义的Pipeline\n",
    "                         param_grid=param_grid,  # 参数网格\n",
    "                         cv=n_folds,  # 交叉验证折数\n",
    "                         scoring=rmse_score,  # 使用的评分标准是RMSE\n",
    "                         # n_jobs=-1  # 使用所有可用的CPU核心\n",
    "                        )\n",
    "# 使用数据X和y来拟合GridSearchCV估计器\n",
    "estimator.fit(X=X, y=y)\n",
    "\n",
    "# 获取交叉验证的结果\n",
    "cv_results = estimator.cv_results_\n",
    "\n",
    "# 从cv_results中提取每一折的测试得分\n",
    "test_scores = pd.DataFrame({fold: cv_results[f'split{fold}_test_score'] for fold in range(n_folds)}, \n",
    "                           index=n_neighbors).stack().reset_index()\n",
    "test_scores.columns = ['k', 'fold', 'RMSE']\n",
    "\n",
    "# 计算每一个k的平均RMSE\n",
    "mean_rmse = test_scores.groupby('k').RMSE.mean()\n",
    "# 获取最佳的k和对应的最佳得分\n",
    "best_k, best_score = mean_rmse.idxmin(), mean_rmse.min()\n",
    "\n",
    "# 使用Seaborn绘制交叉验证的结果\n",
    "sns.pointplot(x='k', y='RMSE', data=test_scores, scale=.3, join=False, errwidth=2)\n",
    "plt.title('Cross Validation Results')  # 设置图的标题\n",
    "sns.despine()  # 去除图的顶部和右侧边框，使得可视化效果更好\n",
    "plt.tight_layout()  # 自动调整子图参数，使得子图适应图的区域\n",
    "plt.gcf().set_size_inches(10, 5)  # 设置图的大小\n",
    "\n",
    "### 使用yellowbrick库来绘制训练和验证曲线\n",
    "# 创建一个大图，用于绘制验证曲线\n",
    "fig, ax = plt.subplots(figsize=(16, 9))\n",
    "\n",
    "# 生成并显示验证曲线\n",
    "val_curve = ValidationCurve(KNeighborsRegressor(),   # 使用KNN回归模型\n",
    "                      param_name='n_neighbors',      # 需要调整的参数是邻居数量\n",
    "                      param_range=n_neighbors,       # 参数的范围\n",
    "                      cv=5,                          # 交叉验证折数\n",
    "                      scoring=rmse_score,            # 使用的评分标准是RMSE\n",
    "                        n_jobs=-1,                   # 使用所有可用的CPU核心\n",
    "                      ax=ax)                         # 在上面创建的图上绘制\n",
    "val_curve.fit(X, y)       # 使用数据X和y来拟合验证曲线\n",
    "val_curve.poof()          # 显示图像\n",
    "sns.despine()             # 去除图的顶部和右侧边框，使得可视化效果更好\n",
    "fig.tight_layout()       # 自动调整子图参数，使得子图适应图的区域\n",
    "\n",
    "# 创建另一个大图，用于绘制学习曲线\n",
    "fig, ax = plt.subplots(figsize=(16, 9))\n",
    "\n",
    "# 生成并显示学习曲线\n",
    "l_curve = LearningCurve(KNeighborsRegressor(n_neighbors=best_k),  # 使用之前找到的最佳邻居数量的KNN回归模型\n",
    "                        train_sizes=np.arange(.1, 1.01, .1),      # 训练数据的大小范围\n",
    "                        scoring=rmse_score,                        # 使用的评分标准是RMSE\n",
    "                        cv=5,                                     # 交叉验证折数\n",
    "                        n_jobs=-1,                              # 使用所有可用的CPU核心\n",
    "                        ax=ax)                                    # 在上面创建的图上绘制\n",
    "l_curve.fit(X, y)        # 使用数据X和y来拟合学习曲线\n",
    "l_curve.poof()           # 显示图像\n",
    "sns.despine()            # 去除图的顶部和右侧边框，使得可视化效果更好\n",
    "fig.tight_layout();      # 自动调整子图参数，使得子图适应图的区域\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### 使用KNN进行二分类任务\n",
    "\n",
    "# 将y转换为二分类标签：如果y大于其中位数则为1，否则为0\n",
    "y_binary = (y>y.median()).astype(int)\n",
    "\n",
    "# 设置KNN分类器中的邻居数量从5到150，每10个一跳\n",
    "n_neighbors = tuple(range(5, 151, 10))\n",
    "\n",
    "# 设置交叉验证的折数为5\n",
    "n_folds = 5\n",
    "\n",
    "# 使用的评分标准是ROC曲线下面积\n",
    "scoring = 'roc_auc'\n",
    "\n",
    "# 创建一个Pipeline，首先进行标准化，然后用KNN分类器\n",
    "pipe = Pipeline([('scaler', StandardScaler()),  # 标准化数据\n",
    "                 ('knn', KNeighborsClassifier())])  # KNN分类模型\n",
    "\n",
    "# 创建参数网格，用于GridSearchCV\n",
    "param_grid = {'knn__n_neighbors': n_neighbors}\n",
    "\n",
    "# 创建GridSearchCV估计器，用于寻找最佳参数\n",
    "estimator = GridSearchCV(estimator=pipe,  # 使用上面定义的Pipeline\n",
    "                         param_grid=param_grid,  # 参数网格\n",
    "                         cv=n_folds,  # 交叉验证折数\n",
    "                         scoring=scoring,  # 使用的评分标准是ROC曲线下面积\n",
    "#                          n_jobs=-1  # 使用所有可用的CPU核心\n",
    "                        )\n",
    "# 使用数据X和y_binary来拟合GridSearchCV估计器\n",
    "estimator.fit(X=X, y=y_binary)\n",
    "\n",
    "# 获取最佳的邻居数量\n",
    "best_k = estimator.best_params_['knn__n_neighbors']\n",
    "\n",
    "# 创建一个大图，用于绘制验证曲线\n",
    "fig, ax = plt.subplots(figsize=(16, 9))\n",
    "\n",
    "# 生成并显示验证曲线\n",
    "val_curve = ValidationCurve(KNeighborsClassifier(),   # 使用KNN分类模型\n",
    "                      param_name='n_neighbors',       # 需要调整的参数是邻居数量\n",
    "                      param_range=n_neighbors,        # 参数的范围\n",
    "                      cv=n_folds,                     # 交叉验证折数\n",
    "                      scoring=scoring,                # 使用的评分标准是ROC曲线下面积\n",
    "#                       n_jobs=-1,                    # 使用所有可用的CPU核心\n",
    "                      ax=ax)                          # 在上面创建的图上绘制\n",
    "val_curve.fit(X, y_binary)  # 使用数据X和y_binary来拟合验证曲线\n",
    "val_curve.poof()            # 显示图像\n",
    "sns.despine()               # 去除图的顶部和右侧边框，使得可视化效果更好\n",
    "fig.tight_layout()          # 自动调整子图参数，使得子图适应图的区域\n",
    "\n",
    "# 创建另一个大图，用于绘制学习曲线\n",
    "fig, ax = plt.subplots(figsize=(16, 9))\n",
    "\n",
    "# 生成并显示学习曲线\n",
    "l_curve = LearningCurve(KNeighborsClassifier(n_neighbors=best_k),  # 使用之前找到的最佳邻居数量的KNN分类模型\n",
    "                        train_sizes=np.arange(.1, 1.01, .1),       # 训练数据的大小范围\n",
    "                        scoring=scoring,                            # 使用的评分标准是ROC曲线下面积\n",
    "                        cv=5,                                      # 交叉验证折数\n",
    "#                         n_jobs=-1,                               # 使用所有可用的CPU核心\n",
    "                        ax=ax)                                     # 在上面创建的图上绘制\n",
    "l_curve.fit(X, y_binary)   # 使用数据X和y_binary来拟合学习曲线\n",
    "l_curve.poof()             # 显示图像\n",
    "sns.despine()              # 去除图的顶部和右侧边框，使得可视化效果更好\n",
    "fig.tight_layout()        # 自动调整子图参数，使得子图适应图的区域\n",
    "\n",
    "### 引入所需的评价指标函数\n",
    "from sklearn.metrics import (classification_report,\n",
    "                             accuracy_score,\n",
    "                             zero_one_loss,\n",
    "                             roc_auc_score,\n",
    "                             roc_curve,\n",
    "                             brier_score_loss,\n",
    "                             cohen_kappa_score,\n",
    "                             confusion_matrix,\n",
    "                             fbeta_score,\n",
    "                             hamming_loss,\n",
    "                             hinge_loss,\n",
    "                             jaccard_score,\n",
    "                             log_loss,\n",
    "                             matthews_corrcoef,\n",
    "                             f1_score,\n",
    "                             average_precision_score,\n",
    "                             precision_recall_curve)\n",
    "\n",
    "# 使用交叉验证预测每个样本的概率（这里只提取为正类的概率）\n",
    "y_score = cross_val_predict(KNeighborsClassifier(best_k), \n",
    "                           X=X, \n",
    "                           y=y_binary, \n",
    "                           cv=5, \n",
    "                           n_jobs=-1, \n",
    "                           method='predict_proba')[:, 1]\n",
    "\n",
    "# 使用预测的概率构建字典\n",
    "pred_scores = dict(y_true=y_binary,y_score=y_score)\n",
    "\n",
    "# 计算ROC AUC\n",
    "roc_auc_score(**pred_scores)\n",
    "\n",
    "# 计算ROC曲线的各个值\n",
    "cols = ['False Positive Rate', 'True Positive Rate', 'threshold']\n",
    "roc = pd.DataFrame(dict(zip(cols, roc_curve(**pred_scores))))\n",
    "\n",
    "# 计算Precision和Recall曲线的值\n",
    "precision, recall, ts = precision_recall_curve(y_true=y_binary, probas_pred=y_score)\n",
    "pr_curve = pd.DataFrame({'Precision': precision, 'Recall': recall})\n",
    "\n",
    "# 优化阈值以获得最大的F1分数\n",
    "f1 = pd.Series({t: f1_score(y_true=y_binary, y_pred=y_score>t) for t in ts})\n",
    "best_threshold = f1.idxmax()\n",
    "\n",
    "# 绘制ROC、Precision-Recall、F1分数曲线\n",
    "roc.info()\n",
    "\n",
    "fig, axes = plt.subplots(ncols=3, figsize=(15, 5))\n",
    "ax = sns.scatterplot(x='False Positive Rate', y='True Positive Rate', data=roc, size=5, legend=False, ax=axes[0])\n",
    "axes[0].plot(np.linspace(0,1,100), np.linspace(0,1,100), color='k', ls='--', lw=1)\n",
    "axes[0].fill_between(y1=roc['True Positive Rate'], x=roc['False Positive Rate'], alpha=.5,color='darkred')\n",
    "axes[0].set_title('Receiver Operating Characteristic')\n",
    "\n",
    "\n",
    "sns.scatterplot(x='Recall', y='Precision', data=pr_curve, ax=axes[1])\n",
    "axes[1].set_ylim(0,1)\n",
    "axes[1].set_title('Precision-Recall Curve')\n",
    "\n",
    "\n",
    "f1.plot(ax=axes[2], title='F1 Scores', ylim=(0,1))\n",
    "axes[2].set_xlabel('Threshold')\n",
    "axes[2].axvline(best_threshold, lw=1, ls='--', color='k')\n",
    "axes[2].text(s=f'Max F1 @ {best_threshold:.2f}', x=.5, y=.95)\n",
    "sns.despine()\n",
    "fig.tight_layout()\n",
    "\n",
    "\n",
    "# 计算平均精度\n",
    "average_precision_score(y_true=y_binary, y_score=y_score)\n",
    "\n",
    "# 计算Brier分数\n",
    "brier_score_loss(y_true=y_binary, y_prob=y_score)\n",
    "\n",
    "# 使用最佳阈值转化概率为预测类别\n",
    "y_pred = y_score > best_threshold\n",
    "scores = dict(y_true=y_binary, y_pred=y_pred)\n",
    "\n",
    "# 计算F-beta分数\n",
    "fbeta_score(**scores, beta=1)\n",
    "\n",
    "# 打印分类报告（包含精度、召回率、F1分数等）\n",
    "print(classification_report(**scores))\n",
    "\n",
    "# 计算混淆矩阵\n",
    "confusion_matrix(**scores)\n",
    "# 计算准确率\n",
    "accuracy_score(**scores)\n",
    "# 计算0-1损失\n",
    "zero_one_loss(**scores)\n",
    "# 计算Hamming损失\n",
    "hamming_loss(**scores)\n",
    "# 计算Cohen's Kappa\n",
    "cohen_kappa_score(y1=y_binary, y2=y_pred)\n",
    "# 计算Hinge损失\n",
    "hinge_loss(y_true=y_binary, pred_decision=y_pred)\n",
    "# 计算Jaccard相似度\n",
    "jaccard_score(**scores)\n",
    "# 计算Log Loss / 交叉熵损失\n",
    "log_loss(**scores)\n",
    "# 计算Matthews相关系数\n",
    "matthews_corrcoef(**scores)\n",
    "\n",
    "### Multi-Class \n",
    "y_multi = pd.qcut(y, q=3, labels=[0,1,2])\n",
    "n_neighbors = tuple(range(5, 151, 10))\n",
    "n_folds = 5\n",
    "scoring = 'accuracy'\n",
    "pipe = Pipeline([('scaler', StandardScaler()), \n",
    "                 ('knn', KNeighborsClassifier())])\n",
    "\n",
    "param_grid = {'knn__n_neighbors': n_neighbors}\n",
    "\n",
    "estimator = GridSearchCV(estimator=pipe,\n",
    "                         param_grid=param_grid,\n",
    "                         cv=n_folds,\n",
    "                         n_jobs=-1\n",
    "                        )\n",
    "estimator.fit(X=X, y=y_multi)\n",
    "\n",
    "y_pred = cross_val_predict(estimator.best_estimator_, \n",
    "                           X=X, \n",
    "                           y=y_multi, \n",
    "                           cv=5, \n",
    "                           n_jobs=-1, \n",
    "                           method='predict')\n",
    "print(classification_report(y_true=y_multi, y_pred=y_pred))\n",
    "\n",
    "\n",
    "\n",
    "### 使用多分类方法\n",
    "\n",
    "# 将连续的y值分为3个区间，每个区间对应一个类标签\n",
    "y_multi = pd.qcut(y, q=3, labels=[0,1,2])\n",
    "\n",
    "# 设置KNN分类器中的邻居数量从5到150，每10个一跳\n",
    "n_neighbors = tuple(range(5, 151, 10))\n",
    "\n",
    "# 设置交叉验证的折数为5\n",
    "n_folds = 5\n",
    "\n",
    "# 使用的评分标准是准确度\n",
    "scoring = 'accuracy'\n",
    "\n",
    "# 创建一个Pipeline，首先进行标准化，然后用KNN分类器\n",
    "pipe = Pipeline([('scaler', StandardScaler()),  # 标准化数据\n",
    "                 ('knn', KNeighborsClassifier())])  # KNN分类模型\n",
    "\n",
    "# 创建参数网格，用于GridSearchCV\n",
    "param_grid = {'knn__n_neighbors': n_neighbors}\n",
    "\n",
    "# 创建GridSearchCV估计器，用于寻找最佳参数\n",
    "estimator = GridSearchCV(estimator=pipe,  # 使用上面定义的Pipeline\n",
    "                         param_grid=param_grid,  # 参数网格\n",
    "                         cv=n_folds,  # 交叉验证折数\n",
    "                         n_jobs=-1  # 使用所有可用的CPU核心\n",
    "                        )\n",
    "\n",
    "# 使用数据X和y_multi来拟合GridSearchCV估计器\n",
    "estimator.fit(X=X, y=y_multi)\n",
    "\n",
    "# 使用交叉验证预测每个样本的类标签\n",
    "y_pred = cross_val_predict(estimator.best_estimator_, \n",
    "                           X=X, \n",
    "                           y=y_multi, \n",
    "                           cv=5, \n",
    "                           n_jobs=-1, \n",
    "                           method='predict')\n",
    "\n",
    "# 打印分类报告（包含精度、召回率、F1分数等）\n",
    "print(classification_report(y_true=y_multi, y_pred=y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
